---
layout: post
comments: true
title: Helm, Kubernetes, et les systÃ¨mes de fichier multiniveau
type: post
tags: [kubernetes, docker]
lang: fr
image: /images//post/2020/03/2020-03-18-helm-filesystem-multin-niveau.png
---

Dans cet article nous allons traiter de la mise en place d'un systÃ¨me de fichier multiniveau au sein d'une image docker dans un contexte Kubernetes, avec un dÃ©ploiement kind.

# ProblÃ©matique

Bien souvent, il convient lors du dÃ©ploiement d'une application sous Kubernetes de s'assurer que les fichiers de configuration applicatifs soient prÃ©sents sur l'image. Certes, il n'est pas prÃ©conisÃ© d'injecter de la configuration par systÃ¨me de fichier (on prÃ©fÃ¨re souvent les variables d'environnement), mais quand on porte une application sous k8s c'est hÃ©las souvent une problÃ©matique Ã  laquelle on est confrontÃ©. D'autant que les dit fichiers doivent Ã©voluÃ©s en fonction des environnements de dÃ©ploiement.

Une approche simple consisterait Ã  mettre en place une config map par fichier, mais, le travail peut Ãªtre long et fastidieux quand on est dans le cas de plusieurs dizaines de fichiers.

Je vous prÃ©sente donc ici la solution que j'ai mise en oeuvre dans de multiples projets pour me simplifier la tÃ¢che.

# PrÃ©requis

Voici la liste de prÃ©requis pour le ce tutoriel:

1. disposer d'un environnement Kubernetes, nous utiliserons [k3d](https://k3d.io/) ici
2. avoir des connaissances sur la solution de dÃ©ploiement HELM
3. maitriser les concepts Kubernetes de configuration map / dÃ©ploiement / ...

# Solution

Nous allons mettre en place un mÃ©canisme de construction dynamique de configuration map que nous allons ensuite monter dans une image. Les fichiers prÃ©sentÃ©s dans la configuration map seront des fichiers texte dans lequel il conviendra de changer le contenu en fonction de valeur dÃ©finie dans le fichier de values.yaml du chart.

# DÃ©finition de l'attendu

Pour illustrer notre configuration map multiniveau nous allons construire dans un container le filesystem suivant:

```bash
App
 â”£ subfolder
 â”ƒ â”— file3.cfg
 â”£ file1.cfg
 â”— file2.cfg
```

Dans le file1.cfg nous allons faire en sorte d'injecter des donnÃ©es de configuration en provenance du fichier de configuration du chart : le fichier values.yaml

# Ã‰tape du tutoriel

## Installation de k3d

AprÃ¨s avoir installÃ© l'outil k3d en suivant la [procÃ©dure d'installation](https://k3d.io), vÃ©rifiez la bonne installation de l'outil en lanÃ§ant la commande suivante:

```bash
k3d --version
```

Vous devez obtenir le rÃ©sultat suivant:

```bash
k3d version v3.2.0
k3s version v1.18.9-k3s1 (default)
```

CrÃ©er votre premier cluster en lanÃ§ant la commande

```bash
k3d cluster create mycluter
```

qui vous donne le rÃ©sultat suivant:

![CrÃ©ation cluster k3d](/blog/images/post/2020/03/2020-03-18-helm-filesystem-multin-niveau-1.png)

vous devez pouvoir voir la liste des pods de votre tout nouveau cluster en lanÃ§ant la commande suivante:

```bash
kubectl get pods --all-namespaces
```

qui vous donne ce rÃ©sultat:

![Liste des pods du cluster](/blog/images/post/2020/03/2020-03-18-helm-filesystem-multin-niveau-2.png)

## Installation de HELM3

La procÃ©dure d'installation de l'outil est prÃ©sente ici [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/).

Dans mon cas je suis sur une machine Ubuntu je lance donc simplement le script suivant comme indiquÃ© dans la documentation:

```bash
curl https://baltocdn.com/helm/signing.asc | sudo apt-key add -
sudo apt-get install apt-transport-https --yes
echo "deb https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm
```

vous pouvez vÃ©rifier que helm3 est correctement installÃ© en lanÃ§ant la commande suivante:

```bash
helm version
```

Qui doit vous retourner l'information suivante:

```bash
version.BuildInfo{Version:"v3.5.1", GitCommit:"32c22239423b3b4ba6706d450bd044baffdcf9e6", GitTreeState:"clean", GoVersion:"go1.15.7"}
```

## CrÃ©ation du chart Ã  partir du modÃ¨le

Passons maintenant Ã  la mise en place du chart helm Ã  proprement dit. CrÃ©ez un dossier de projet, dans lequel nous allons travailler.

```bash
mkdir ~/home/multilevel && cd ~/home/multilevel
```

et lancer la commande de crÃ©ation du chart Helm:

```bash
helm create multilevelcm
```

Cette commande crÃ©e le squelette du chart dans le dossier `~/home/multilevel/`.

vous obtenez la structure de fichier suivante:

```bash
ğŸ“¦multilevelcm
 â”£ ğŸ“‚charts
 â”£ ğŸ“‚templates
 â”ƒ â”£ ğŸ“‚tests
 â”ƒ â”ƒ â”— ğŸ“œtest-connection.yaml
 â”ƒ â”£ ğŸ“œNOTES.txt
 â”ƒ â”£ ğŸ“œ_helpers.tpl
 â”ƒ â”£ ğŸ“œdeployment.yaml
 â”ƒ â”£ ğŸ“œhpa.yaml
 â”ƒ â”£ ğŸ“œingress.yaml
 â”ƒ â”£ ğŸ“œservice.yaml
 â”ƒ â”— ğŸ“œserviceaccount.yaml
 â”£ ğŸ“œ.helmignore
 â”£ ğŸ“œChart.yaml
 â”— ğŸ“œvalues.yaml
```

il s'agit d'un chart de base qui crÃ©e dÃ©ploie un serveur nginx.

Pour plus d'information sur l'anatomie des chart la documentation est ici [https://helm.sh/docs/helm/helm_create/](https://helm.sh/docs/helm/helm_create/).

## CrÃ©ation de la configuration map dynamique

### crÃ©ation de la structure de fichier dans le chart

Dans le dossier de chart, crÃ©er un dossier files qui contient la structure de notre dossier. Vous devez obtenir la structure de fichier suivant:

```bash
ğŸ“¦multilevelcm
 â”£ ğŸ“‚charts
 â”£ ğŸ“‚files
 â”ƒ â”£ ğŸ“‚subfolder
 â”ƒ â”ƒ â”— ğŸ“œfile3.cfg
 â”ƒ â”£ ğŸ“œfile1.cfg
 â”ƒ â”— ğŸ“œfile2.cfg
 â”£ ğŸ“‚templates
 â”ƒ â”£ ğŸ“‚tests
 â”ƒ â”ƒ â”— ğŸ“œtest-connection.yaml
 â”ƒ â”£ ğŸ“œNOTES.txt
 â”ƒ â”£ ğŸ“œ_helpers.tpl
 â”ƒ â”£ ğŸ“œdeployment.yaml
 â”ƒ â”£ ğŸ“œhpa.yaml
 â”ƒ â”£ ğŸ“œingress.yaml
 â”ƒ â”£ ğŸ“œservice.yaml
 â”ƒ â”— ğŸ“œserviceaccount.yaml
 â”£ ğŸ“œ.helmignore
 â”£ ğŸ“œChart.yaml
 â”— ğŸ“œvalues.yaml
```

Dans les fichiers `file2.cfg` et `file3.cfg` mettez le contenu que vous souhaitez. Dans le `file1.cfg`, positionnez le contenu suivant:

```bash
{% raw %}
{{ .Values.configuration.file1 }}
{% endraw %}
```

Ceci permettra au moteur de template d'aller chercher la valeur dans le fichier de chart. Pour cela Ã  la fin du fichier values.yaml, ajoutez le contenu suivant:

```yaml
configuration:
  file1: |-
    contenu du fichier 1
```

### crÃ©ation de la configmap

Dans le dossier du Chart, crÃ©er un dossier configmap pour loger le fichier de dÃ©finition de notre objet.

dans ce fichier, positionner le contenu suivant:

```yaml
{% raw %}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "multilevelcm.fullname" . }}-config
  labels:
    {{- include "multilevelcm.labels" . | nindent 4 }}
data:
  {{ $root := . }}
  {{- range $path, $bytes := $root.Files.Glob (printf "files/**") -}}
  {{ $name := base $path }}
  {{- sha256sum (printf "%s" (index (regexSplit "files/" ($path) -1 ) 1))}}{{ print ": |- " }}
    {{- tpl ($root.Files.Get ($path)) $ | nindent 4 }}
  {{end }}
{% endraw %}
```

l'usage de la fonction sha256sum permet de s'affranchir des caractÃ¨res spÃ©ciaux Ã©ventuels dans le nom du fichier. La fonction tpl permet de considÃ©rer les fichiers comme des templates helm et donc d'y injecter des donnÃ©es en provenance du helm chart.

## montage de la configuration map dans le pod

Il reste a monter la configuration map en tant que volume dans le container. Pour ce faire, Ã©diter le fichier de dÃ©ploiement pour y ajouter les Ã©lÃ©ments suivants:

Dans la partie du container, ajouter la dÃ©claration du module:

```yaml
containers:
  - name: {{ .Chart.Name }}
      securityContext:
      {{- toYaml .Values.securityContext | nindent 12 }}
      image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart  AppVersion }}"
      imagePullPolicy: {{ .Values.image.pullPolicy }}
      ports:
      - name: http
        containerPort: 80
        protocol: TCP
      livenessProbe:
      httpGet:
        path: /
        port: http
      readinessProbe:
      httpGet:
        path: /
        port: http
      resources:
      {{- toYaml .Values.resources | nindent 12 }}
      volumeMounts:
      - name: config
        mountPath: "/app"
```

puis Ã  la fin du fichier ajouter la dÃ©claration du volume:

```yaml
{% raw %}
volumes:
- name: config
  configMap:
    name: {{ include "multilevelcm.fullname" . }}-config
    items:
    {{- range $path, $bytes := .Files.Glob (printf "files/**") -}}
    {{ $name := base $path }}
        - key: {{ sha256sum (printf "%s" (index (regexSplit "files/" ($path) -1) 1)) }}
        path: {{ printf "%s" (index (regexSplit "files/" ($path) -1) 1) }}
    {{- end}}
{% endraw %}
```

## RÃ©sultat

Notre chart est pret, pour le dÃ©ployer sur le cluster k3d. positionnez vous dans votre dossier ~/multilevel et lancer la commande suivante:

```bash
helm install -name myrelease -n myrelease --create-namespace ./multilevelcm/
```

Avec l'outil [lens](https://k8slens.dev/) connectez vous sur votre cluster, puis entrez dans votre pod. En navigant dans le dossier /app, vous constatez que tout vos fichiers sont la et que le contenu de votre fichier file1.cfg corresponds Ã  ce que vous avez mis dans le fichier de values.

![resultat](/blog/images/post/2020/03/2020-03-18-helm-filesystem-multin-niveau-3.png)

le code du chart est disponible sur mon [github](https://github.com/matthieupetite/kubernetes-multilevel-configurationmap)
